
<html><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
	
	<title>Prof. Dr. Xiaogang Cheng</title>
	<meta content="Xiaogang Cheng, chengxg-vision.github.io" name="keywords">
	<style media="screen" type="text/css">html, body, div, span, applet, object, iframe, h1, h2, h3, h4, h5, h6, p, blockquote, pre, a, abbr, acronym, address, big, cite, code, del, dfn, em, font, img, ins, kbd, q, s, samp, small, strike, strong, sub, tt, var, dl, dt, dd, ol, ul, li, fieldset, form, label, legend, table, caption, tbody, tfoot, thead, tr, th, td {
  border: 0pt none;
  font-family: inherit;
  font-size: 100%;
  font-style: inherit;
  font-weight: inherit;
  margin: 0pt;
  outline-color: invert;
  outline-style: none;
  outline-width: 0pt;
  padding: 0pt;
  vertical-align: baseline;
}

a {
  color: #1772d0;
  text-decoration:none;
}

a:focus, a:hover {
  color: #f09228;
  text-decoration:none;
}

a.paper {
  font-weight: bold;
  font-size: 12pt;
}

b.paper {
  font-weight: bold;
  font-size: 12pt;
}

* {
  margin: 0pt;
  padding: 0pt;
}

body {
  position: relative;
  margin: 3em auto 2em auto;
  width: 800px;
  font-family: Lato, Verdana, Helvetica, sans-serif;
  font-size: 14px;
  background: #eee;
}

h2 {
  font-family: Lato, Verdana, Helvetica, sans-serif;
  font-size: 15pt;
  font-weight: 700;
}

h3 {
  font-family: Lato, Verdana, Helvetica, sans-serif;
  font-size: 16px;
  font-weight: 700;
}

strong {
  font-family: Lato, Verdana, Helvetica, sans-serif;
  font-size: 13px;
  font-weight:bold;
}

ul { 
  list-style: circle;
}

img {
  border: none;
}

li {
  padding-bottom: 0.5em;
  margin-left: 1.4em;
}

alert {
  font-family: Lato, Verdana, Helvetica, sans-serif;
  font-size: 13px;
  font-weight: bold;
  color: #FF0000;
}

em, i {
	font-style:italic;
}

div.section {
  clear: both;
  margin-bottom: 1.5em;
  background: #eee;
}

div.spanner {
  clear: both;
}

div.paper {
  clear: both;
  margin-top: 0.5em;
  margin-bottom: 1em;
  border: 1px solid #ddd;
  background: #fff;
  padding: 1em 1em 1em 1em;
}

div.paper div {
  padding-left: 230px;
}

img.paper {
  margin-bottom: 0.5em;
  float: left;
  width: 200px;
}

span.blurb {
  font-style:italic;
  display:block;
  margin-top:0.75em;
  margin-bottom:0.5em;
}

pre, code {
  font-family: 'Lucida Console', 'Andale Mono', 'Courier', monospaced;
  margin: 1em 0;
  padding: 0;
}

div.paper pre {
  font-size: 0.9em;
}
</style>

<link href="./Chengxg_Resource/css" rel="stylesheet" type="text/css">
<script async="" src="./Chengxg_Resource/analytics.js.download"></script><script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-45959174-3', 'chengxg-vision.github.io');
  ga('send', 'pageview');
</script>


<!-- 统计访问量的百度代码 >—-->
<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?3fa7ee25259b1d183078df2bb7530fee";
  var s = document.getElementsByTagName("script")[0]; 
  s.parentNode.insertBefore(hm, s);
})();
</script>   <!-- 统计访问量的百度代码 >—-->
</head>


<!-- the content above is document head >—-->
<p><b> English Version <a href="./Chengxg_Chinese.html">中文版</a></b></p>


<!-- start of the 1st box >—-->
<body>
<div style="margin-bottom: 1em; border: 1px solid #ddd; background-color: #fff; padding: 1em; height: 360px;">
<div style="margin: 0px auto; width: 100%;">
<img title="Chengxg" style="float: right; padding-left: 0.01em; height: 300px;" src="./Chengxg_Resource/chengxg-portrait.jpg">
<div style="padding-left: 0em; vertical-align: top; height: 120px;">
<span style="line-height: 150%; font-size: 18pt;" >Prof. Dr. Xiaogang Cheng (成孝刚)</span><br>
<br /> <!-- for generating blank line -->

<p><b>Now, I am an Associate Professor of computer vision and M. S. student supervisor at <a href="http://www.njupt.edu.cn/"> Nanjing University of Posts and Telecommunications(NUPT).</a></b></p>
<br /> <!-- for generating blank line -->

<p><b>Research interests: 1)Vision-based non-invasive perception for human thermal comfort 2)Foggy and hazy visibility perception, Reflection removal.</b></p> 
<br /> <!-- for generating blank line -->

<p><b>Experience: 1)Research Fellow@<a href='http://www.vision.ee.ethz.ch/en/'>Computer Vision Lab, ETH Zürich</a>. Supervisor: Prof. Luc Van Gool, 2)Postdoc@<a href='https://www.kth.se/en'>KTH Royal Institute of Technology, Sweden</a>, 3)Ph.D.@<a href='https://www.nju.edu.cn/'>Nanjing University</a> and B.E.@<a href='https://www.seu.edu.cn/'>Southeast University</a>.</b></p>
<br /> <!-- for generating blank line -->

<p><b>Contact: 1)E-mail: chengx@vision.ee.ethz.ch, xiacheng@kth.se, Chengxg@njupt.edu.cn, 2)Phone: +86 138 1337 2706</b></p>
<br /> <!-- for generating blank line -->

<p><b>Welcome to join my academic research group!</b></p>
<a href="https://scholar.google.se/citations?hl=zh-CN&user=y6SrwJgAAAAJ&view_op=list_works&sortby=pubdate"> [Google Scholar Profile]</a>

<!-- 
<span><strong>Office</strong>: CS Building 506 </span><br>
<span><strong>Email</strong>: lmwang.nju [at] gmail.com</span> <br> 
-->
</div>
</div>
</div>
<!--<div style="clear: both; background-color: #fff; margin-top: 1.5em; padding: .2em; padding-left: .3em;">-->
<!-- end of the 1st box >—-->


<!-- start of the 2nd box >—-->
<div style="clear: both;">
<div class="section">
  <h2>Research interests</h2>
  <div class="paper">
  	<p><b>Main interests: Artificial Intelligence (AI) and Computer vision (CV)</b></p>
	<br />
	<p style="line-height: 140%"><b>Topic 1. Non-invasive thermal comfort perception for humanistic intelligent building</b></p>
    <span style="line-height: 140%"><strong>[1]&nbsp;&nbsp;Project:&nbsp;</strong>Non-invasive thermal comfort perception based on deep learning.</span><br>
    <span style="line-height: 140%"><strong>[2]&nbsp;&nbsp;Methodology:&nbsp;</strong>Machine learning (Deep Learning), computer vision.</span><br>
    <span style="line-height: 140%"><strong>[3]&nbsp;&nbsp;Interdisciplinary subjects:&nbsp;</strong>Computer vision, machine learning and building physics.</span><br>
    <span style="line-height: 140%"><strong>[4]&nbsp;&nbsp;Motivation:&nbsp;</strong>Energy saving, Human-centered indoor environment (buildings, vehicles).</span><br>
    <span style="line-height: 140%"><strong>[5]&nbsp;&nbsp;Philosophical idea:&nbsp;</strong>Thermal comfort through perception.</span><br>
    <span style="line-height: 140%"><strong>[6]&nbsp;&nbsp;Cooperation institutions:&nbsp;</strong>ETHZ Switzerland, KTH Sweden, UMU Sweden, LBNL USA, XAUAT China</span><br>
    <br />
    <p style="line-height: 140%"><b>Topic 2. Defogging and fogy visibility estimation for intelligent transportation</b></p>
	<span style="line-height: 140%"><strong>[1]&nbsp;&nbsp;Project:&nbsp;</strong>Hazy visibility estimation and defogging based on deep learning and computer vision.</span><br>
    <span style="line-height: 140%"><strong>[2]&nbsp;&nbsp;Methodology:&nbsp;</strong>Machine learning (Deep Learning), computer vision.</span><br>
    <span style="line-height: 140%"><strong>[3]&nbsp;&nbsp;Interdisciplinary subjects:&nbsp;</strong>Computer vision, intelligent transportation and atmospheric sciences.</span><br>
    <span style="line-height: 140%"><strong>[4]&nbsp;&nbsp;Motivation:&nbsp;</strong>Reduce traffic accidents, serve self-driving cars.</span><br>
    <span style="line-height: 140%"><strong>[5]&nbsp;&nbsp;Cooperation institutions:&nbsp;</strong> ETHZ Switzerland, KTH Sweden.</span><br>
    <br />
  </div>
</div>
</div>
<!-- end of the 2nd box >—-->

<!-- start of the 3rd box >—-->
<div style="clear: both;">
<div class="section">
  <h2>Main academic contributions</h2>
  <div class="paper">
 	<span style="line-height: 140%"><strong>Build a new research sub-direction between computer vision and building physics.&nbsp;</strong> For overcoming the drawbacks of current methods (invasive or semi-invasive, non-human-centered), we proposed vision-based non-invasive perception for human thermal comfort in Oct. 2016.</span><br>
    <br />
	
    <span style="line-height: 140%"><strong>Construct algorithms.&nbsp;</strong>For overcoming the corresponding challenges, several algorithms were proposed. The challenges of human thermal comfort perception are 1) inter-individual difference, 2) intra-individual difference, and 2) subtle variation of skin texture.</span><br>
    <br />
  </div>
</div>
</div>
<!-- end of the 3rd box >—-->



<!-- start of the 4th box >—-->
<div style="clear: both;">
<div class="section">
<h2 id="confpapers">Publications (Recent 3 years, first autor) </h2>

<div class="paper" id="MOC-Dector"><img class="paper" src="./Chengxg_Resource/NIDL.png" title="">
<div> <strong>NIDL: A pilot study of contactless measurement of skin temperature for intelligent building((SCI, JCR Q1, cited: 2))</strong><br>
Xiaogang Cheng, Bin Yang, Anders Hedman, Thomas Olofsson, Haibo Li, Luc Van Gool<br>
Energy & Buildings, 2019. <br>
[ <a href="https://doi.org/10.1016/j.enbuild.2019.06.007">Paper</a> ] [ Code ] <br>
<alert>A contactless measuring method based on subtleness magnification and deep learning (NIDL) was designed to achieve a comfortable, energy efficient built environment.</alert>
</div>
<div class="spanner"></div>
</div>


<div class="paper" id="Liu"><img class="paper" src="./Chengxg_Resource/3_1.png">
<div> <strong>A Contactless Measuring Method of Skin Temperature based on the Skin Sensitivity Index and Deep Learning(SCI, JCR Q4)</strong><br>
Xiaogang Cheng, Bin Yang, Kaige Tan, Erik Isaksson, Liren Li, Anders Hedman, Thomas Olofsson,Haibo Li <br>
Appl. Sci. 2019<br>
[ <a href="https://doi.org/10.3390/app9071375">Paper</a> ] [ Code ] <br>
<alert>A contactless measuring method based on a skin sensitivity index and deep
learning (NISDL) was proposed to measure real-time skin temperature.</alert>
</div>
<div class="spanner"></div>
</div>


<div class="paper" id="V4D"><img class="paper" src="./Chengxg_Resource/skin.png" title="">
<div> <strong>A pilot study of online non-invasive measuring technology based on
video magnification to determine skin temperature(SCI, JCR Q1, cited: 17)</strong><br>
Xiaogang Cheng, Bin Yang, Thomas Olofsson, Guoqing Liu, Haibo Li<br>
Building and Environment, 2017. <br>
[ <a href="https://doi.org/10.1016/j.buildenv.2017.05.021">Paper</a> ] [ Code ] <br>
<alert>Vision-based contactless perception method for human thermal comfort was proposed in the first time and subtleness magnification algorithm was adopted.</alert>
</div>
<div class="spanner"></div>
</div>

<div class="paper" id="Liu"><img class="paper" src="./Chengxg_Resource/fog_haze.png">
<div> <strong>A variational approach to atmospheric visibility estimation in the weather of fog and haze(SCI, JCR Q2, cited: 4)</strong><br>
Xiaogang Cheng, Bin Yang, Guoqing Liu, Thomas Olofsson, Haibo Li<br>
Sustainable Cities and Society, 2018 <br>
[ <a href="https://doi.org/10.1016/j.scs.2018.02.001">Paper</a> ] [ Code ] <br>
<alert>A variational framework
to handle the nature of time-varying extinction coefficient and develop a novel algorithm of extracting the
extinction coefficient through a piecewise functional fitting of observed luminance curves.</alert>
</div>
<div class="spanner"></div>
</div>


<div class="paper" id="Liu"><img class="paper" src="./Chengxg_Resource/fog_haze2.png">
<div> <strong>A Total Bounded Variation Approach to Low Visibility Estimation on Expressways(SCI, JCR Q3)</strong><br>
Xiaogang Cheng, Bin Yang, Guoqing Liu, Thomas Olofsson, Haibo Li<br>
Sensors, 2018 <br>
[ <a href="https://doi.org/10.3390/s18020392">Paper</a> ] [ Code ] <br>
<alert>A total bounded variation (TBV) approach
to estimate low visibility (less than 300 m) is introduced.</alert>
</div>
<div class="spanner"></div>
</div>







</div>
</div>
<!-- start of the 4th box >—-->


<!-- start of the 5th box >—-->
<div style="clear: both;">
<div class="section">
<h2 id="confpapers">Publications (Recent 3 years, second or corresponding author) </h2>

<div class="paper" id="MOC-Dector"><img class="paper" src="./Chengxg_Resource/2_1.png" title="">
<div> <strong>Non-Invasive Assessments of Thermal Discomfort in Real Time</strong><br>
Alan Meier, Xiaogang Cheng, William Dyer, Chris Graham, Thomas Olofsson, Bin Yang<br>
COMFORT AT THE EXTREMES 2019. <br>
[ Paper ] [Code] <br>
<alert>A new method was introduced to assess a person's thermal discomfort based on close observation of human gestures.</alert>
</div>
<div class="spanner"></div>
</div>

<div class="paper" id="V4D"><img class="paper" src="./Chengxg_Resource/2_2.png" title="">
<div> <strong>Real-time and contactless measurements of thermal discomfort based on human poses for energy efficient control of buildings</strong><br>
Bin Yang, Xiaogang Cheng, Dengxin Dai, Thomas Olofsson, Haibo Li, Alan Meier <br>
Building and Environment, 2019 <br>
[ <a href="https://doi.org/10.1016/j.buildenv.2019.106284">Paper</a> ] [ Code] <br>
<alert>This paper examined a contactless method for evaluating a person's thermal sensation revealed by their poses.</alert>
</div>
<div class="spanner"></div>
</div>


</div>
</div>
<!-- start of the 5th box >—-->


<!-- start of the 6th box >—-->
<div style="clear: both;">
<div class="section">
  <h2>Teaching award</h2>
  <div class="paper">
    <span style="line-height: 140%">Dec 2015 &nbsp &nbsp Excellent supervisor of NUPT</span><br>
    <span style="line-height: 140%">May	2015 &nbsp &nbsp 3S Cup College Student competition in internet of things &nbsp &nbsp Third prize (supervisor)</span><br>
	<span style="line-height: 140%">May	2016 &nbsp &nbsp 3S Cup College Student competition in internet of things &nbsp &nbsp Second prize (supervisor)</span><br>
  </div>
</div>
</div>
<!-- end of the 6th box >—-->


<!-- start of the 7th box >—-->
<div style="clear: both;">
<div class="section">
  <h2>Graduates and employers</h2>
  <div class="paper">
	<span style="line-height: 140%"><strong>Master student:&nbsp;</strong>Kai Zhou(2014, <a href="https://www.mediatek.com">@Media Tek</a>), Miaomiao Tan(2014, <a href="https://www.chinamobileltd.com/en/global/home.php">@China mobile</a>), Yun Cheng(2015, <a href="https://home.baidu.com/">@Baidu</a>), Hongjun Lv(2016, <a href="https://www.ly.com/?refid=17089002">@Tongcheng Group</a>), Dezhi Li(2016, <a href="https://www.huawei.com/cn/?ic_medium=direct&ic_source=surlent">@Huawei</a>), Tao Wang(2016, <a href="http://www.kfidc.com/">@SpreadTrum</a>), Lichang Zhang of KTH(2016, <a href="https://www.kunlun.com/index.html">@Kunlun</a>), Kaige Tan of KTH(2017, Ph.D.<a href="https://www.kth.se/">@KTH</a>).</span><br>
    <br />
    
	<span style="line-height: 140%"><strong>Bachelor student: &nbsp;</strong>Zhi Li (2012, Ph.D<a href="https://www.buffalo.edu/">@UB</a>), Nan Huo(2015, Master<a href="https://www.jhu.edu/">@JHU</a>), Yuchen Yang(2015, <a href="https://www.upenn.edu/">@UPenn</a>), Chen Sun(2015, Master<a href="https://uwaterloo.ca/">@Waterlo(UW)</a>), Lin Zhu(2015, Master<a href="http://www.njupt.edu.cn/">@NUPT</a>), Peng Zheng(2015, Master<a href="https://www.unitn.it/en">@UniTrento</a>).</span><br>
    <br />
  </div>
</div>
</div>
<!-- end of the 7th box >—-->


<!-- start of the 8th box >—-->
<div style="clear: both;">
<div class="section">
  <h2>Self-estimate</h2>
  <div class="paper">
	<span style="line-height: 140%">Outgoing, diligent, strong willed and sober personality, Good communication skill and teamwork spirit, Enjoying the challenges of academic study, Untalented but perseverant and indomitable.</span><br>
    <br />
  </div>
</div>
</div>
<!-- end of the 8th box >—-->




<!-- start of the 9th box >—-->
<div style="clear:both;">
<p align="right"><font size="5">Under construction.Last Updated on 18th Jan., 2020</font></p>
<p align="right"><font size="5">Published with <a href="https://pages.github.com/">GitHub Pages</a></font></p>
</div>
<!-- end of the 9th box >—-->

</body></html>